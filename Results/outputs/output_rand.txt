Loading cifar10 dataset.
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Creating lottery-vgg16 model.
Pre-Train for 0 epochs.
Pruning with rand for 1 epochs.
Post-Training for 100 epochs.
Train results:
                 train_loss  test_loss  top1_accuracy      time
Init.      0           NaN   2.417745          11.72  1.552797
Pre-Prune  0           NaN   2.417745          11.72  1.552797
Post-Prune 0           NaN   2.302583          10.00  1.039874
Final      100    0.081614   0.732762          86.79  2.592089
Prune results:
             module   param  ...  score abs sum  prunable
0    layers.0.conv  weight  ...   1.392548e+03      True
1    layers.0.conv    bias  ...   0.000000e+00     False
2    layers.1.conv  weight  ...   2.936300e+04      True
3    layers.1.conv    bias  ...   0.000000e+00     False
4    layers.3.conv  weight  ...   5.876383e+04      True
5    layers.3.conv    bias  ...   0.000000e+00     False
6    layers.4.conv  weight  ...   1.175020e+05      True
7    layers.4.conv    bias  ...   0.000000e+00     False
8    layers.6.conv  weight  ...   2.349841e+05      True
9    layers.6.conv    bias  ...   0.000000e+00     False
10   layers.7.conv  weight  ...   4.717306e+05      True
11   layers.7.conv    bias  ...   0.000000e+00     False
12   layers.8.conv  weight  ...   4.702742e+05      True
13   layers.8.conv    bias  ...   0.000000e+00     False
14  layers.10.conv  weight  ...   9.408946e+05      True
15  layers.10.conv    bias  ...   0.000000e+00     False
16  layers.11.conv  weight  ...   1.882665e+06      True
17  layers.11.conv    bias  ...   0.000000e+00     False
18  layers.12.conv  weight  ...   1.884968e+06      True
19  layers.12.conv    bias  ...   0.000000e+00     False
20  layers.14.conv  weight  ...   1.881908e+06      True
21  layers.14.conv    bias  ...   0.000000e+00     False
22  layers.15.conv  weight  ...   1.882481e+06      True
23  layers.15.conv    bias  ...   0.000000e+00     False
24  layers.16.conv  weight  ...   1.881676e+06      True
25  layers.16.conv    bias  ...   0.000000e+00     False
26              fc  weight  ...   4.060810e+03      True
27              fc    bias  ...   0.000000e+00     False

[28 rows x 13 columns]
Parameter Sparsity: 4657711/14719818 (0.3164)
FLOP Sparsity: 99205065/313478154 (0.3165)
Saving results.
