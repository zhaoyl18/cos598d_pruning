Loading cifar10 dataset.
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Creating lottery-vgg16 model.
Pre-Train for 0 epochs.
Pruning with grasp for 1 epochs.
Post-Training for 300 epochs.
Train results:
                 train_loss     test_loss  top1_accuracy      time
Init.      0           NaN      2.417745          11.72  1.853383
Pre-Prune  0           NaN      2.417745          11.72  1.853383
Post-Prune 0           NaN  59850.002813          10.00  0.619804
Final      300     0.30952      0.535809          82.72  0.794312
Prune results:
             module   param  ...  score abs sum  prunable
0    layers.0.conv  weight  ...       0.259331      True
1    layers.0.conv    bias  ...       0.000000     False
2    layers.1.conv  weight  ...       0.916373      True
3    layers.1.conv    bias  ...       0.000000     False
4    layers.3.conv  weight  ...       1.159111      True
5    layers.3.conv    bias  ...       0.000000     False
6    layers.4.conv  weight  ...       1.147717      True
7    layers.4.conv    bias  ...       0.000000     False
8    layers.6.conv  weight  ...       1.456215      True
9    layers.6.conv    bias  ...       0.000000     False
10   layers.7.conv  weight  ...       1.491146      True
11   layers.7.conv    bias  ...       0.000000     False
12   layers.8.conv  weight  ...       1.307388      True
13   layers.8.conv    bias  ...       0.000000     False
14  layers.10.conv  weight  ...       1.822953      True
15  layers.10.conv    bias  ...       0.000000     False
16  layers.11.conv  weight  ...       2.083792      True
17  layers.11.conv    bias  ...       0.000000     False
18  layers.12.conv  weight  ...       2.115328      True
19  layers.12.conv    bias  ...       0.000000     False
20  layers.14.conv  weight  ...       2.060286      True
21  layers.14.conv    bias  ...       0.000000     False
22  layers.15.conv  weight  ...       1.972834      True
23  layers.15.conv    bias  ...       0.000000     False
24  layers.16.conv  weight  ...       2.233146      True
25  layers.16.conv    bias  ...       0.000000     False
26              fc  weight  ...       0.193924      True
27              fc    bias  ...       0.000000     False

[28 rows x 13 columns]
Parameter Sparsity: 151390/14719818 (0.0103)
FLOP Sparsity: 18372451/313478154 (0.0586)
Saving results.
